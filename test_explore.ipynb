{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test will consist of following.\n",
    "    - filter.\n",
    "        - two keywords likely to return primarely english, and primarely spanish tweets.\n",
    "        - 'warframe' is designated as controll, having large likelyhood of returning multilingual, but primaryly english tweets\n",
    "        - 'Univision' is test as it has a large likelyhood of returning primarely spanish tweets.\n",
    "    - sentiment analysis.\n",
    "        - found interesting project, would be a good refference https://github.com/aylliote/senti-py\n",
    "            - a pretraind model for clasification.. \n",
    "            - runs on various crawlers. seems like a fun idea. . . \n",
    "            - [[future project idea.. at least a more detailed/variable one? . . . (overreach is a thing..)]]\n",
    "        - overall not much testing needed. results were good since start...\n",
    "        - might need to comprehend construction and function of above module in more detail to construct a more, , , addaptive one.\n",
    "    - visualization section \n",
    "        - graphs and pretty things to make some sence of the df.\n",
    "        - histogram for disrtibution, not complicated..\n",
    "        - moving average overtime seems like an iteresting idea..\n",
    "            - as there is the whole date and time column available for the twitter data it should be doable\n",
    "            - just need to mod the twitter pull section.\n",
    "            - then determine the best way to go about it....\n",
    "                - designate start point as general average of given tweets.\n",
    "                - then generate new column as increments. (negative = -1, neutral = 0, possitive = 1 )\n",
    "                - and just graph them as: x = df['datetime'], y = df['sentiment'].average()+df['increment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_langid_warframe.csv')\n",
    "\n",
    "for i in list(df.columns)[1:]:\n",
    "    print(df[i].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_langid_Univision.csv')\n",
    "\n",
    "for i in list(df.columns)[1:]:\n",
    "    print(df[i].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- first run of the language filter is a resouding failure. \n",
    "    - not sure why. no error was raised, \n",
    "    - err likely lies in the try exept components.\n",
    "    - will test with pinted coments before exept pass.\n",
    "- interesting. result from above test only returned  12 instances total.\n",
    "    - ie. 12 instances were the exepts were trigered in 400 tweets.\n",
    "    - these being: 1 triggered once, 2 twice, and 3 thrice....\n",
    "    - stranger still times triggered were the same in both...\n",
    "    - cheked the data, and it was different so it was not that..\n",
    "    - mayhaps an intricacy of the code im not privi to?\n",
    "    - will recheck documentation of modules used in filter\n",
    "    - found error it was in the formating of a section in language.py, easy fix.\n",
    "    - after last test run, desided to cut textblob_safe().\n",
    "        - far to slow and returned too many errors compared to the other two options..\n",
    "-  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from language import langid_safe, langdetect_safe, textblob_safe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('test_langid_Univision.csv')\n",
    "df['test'] = df['tweets'].apply(textblob_safe)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-37e8bf9a3a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Univision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'increment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m alt.Chart(df).mark_line().encode(\n\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from main import twitter_query\n",
    "\n",
    "\n",
    "df = twitter_query('Univision')\n",
    "y = df['increment'].average\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    x = df['datetime'],\n",
    "    y = y + df['increment'],\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit7e56cf6a3162430087e12a19a3617961",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}